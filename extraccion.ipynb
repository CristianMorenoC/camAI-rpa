{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 3 seconds before taking the screenshot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected keyword: 'chat' in text: 'Chat destacado'\n",
      "Screenshot saved as comments_section_auto.png.\n",
      "OCR result for extracted section:\n",
      "Detected text: 'rubius_awaiting - Twitch' with confidence 0.8221718829342818\n",
      "Detected text: '\"P Home' with confidence 0.3536012249027657\n",
      "Detected text: 'WooCommerce' with confidence 0.9987771238079669\n",
      "Detected text: '(27) Learn Italian wit.' with confidence 0.8284670715914711\n",
      "Detected text: 'D Todos los marcadores' with confidence 0.8136375157113005\n",
      "Detected text: 'Chat destacado' with confidence 0.9568096604962775\n",
      "Detected text: 'Lofi Girl' with confidence 0.6942946909367148\n",
      "Detected text: 'New Back-to-School' with confidence 0.9887421846956596\n",
      "Detected text: 'Maram   denji ok good' with confidence 0.8045780898957936\n",
      "Detected text: 'NDragon89' with confidence 0.7111622744398246\n",
      "Detected text: 'Eveningtimes' with confidence 0.9440361485579949\n",
      "Detected text: 'ok give south korea' with confidence 0.9781932567507707\n",
      "Detected text: 'ABGOD' with confidence 0.44619022129290165\n",
      "Detected text: 'UJ Jua' with confidence 0.02543091292694423\n",
      "Detected text: 'Rosi_The_Music_Lover' with confidence 0.9485086044110337\n",
      "Detected text: 'CANT SLEEP AND' with confidence 0.8362298614631611\n",
      "Detected text: 'HAVE A FLIGHT' with confidence 0.8837789461178606\n",
      "Detected text: 'h4 ,sa9al*[snk' with confidence 0.011069205778078453\n",
      "Detected text: '0' with confidence 0.8024279433893753\n",
      "Detected text: '4 Janayl Jeiexal' with confidence 0.13844408211226722\n",
      "Detected text: '2' with confidence 0.3920998162502656\n",
      "Detected text: 'SJs {sm_J' with confidence 0.06668578128452625\n",
      "Detected text: 'Resumir' with confidence 0.9999646752075282\n",
      "Detected text: 'Comprar' with confidence 0.9993469218265646\n",
      "Detected text: 'Lena' with confidence 0.9999271631240845\n",
      "Detected text: 'Yulia relax girl' with confidence 0.9944715210794545\n",
      "Detected text: 'Maram '~4_uu' with confidence 0.1370208422114641\n",
      "Detected text: 'Girl' with confidence 0.9959737062454224\n",
      "Detected text: 'Radios' with confidence 0.9999904125929036\n",
      "Detected text: 'ESP' with confidence 0.9992461922044792\n",
      "Detected text: '5-23' with confidence 0.7566034197807312\n",
      "Detected text: '3 cJp)' with confidence 0.19681645249100937\n",
      "Detected text: 'LAA' with confidence 0.9985700804817627\n",
      "Detected text: '5/09/2024' with confidence 0.9650715658563767\n",
      "Detected text: '4' with confidence 0.18478023094543516\n",
      "Detected text: 'a' with confidence 0.02841364852442041\n",
      "Detected text: 'Hat' with confidence 0.05572828593626687\n",
      "{'rubius_awaiting': '- Twitch', '\"P': 'Home WooCommerce (27) Learn Italian wit. D Todos los marcadores', 'Chat': 'destacado', 'Lofi': 'Girl New Back-to-School', 'Maram': \"'~4_uu\", 'NDragon89': '', 'Eveningtimes': 'ok give south korea', 'ABGOD': '', 'UJ': 'Jua', 'Rosi_The_Music_Lover': 'CANT SLEEP AND HAVE A FLIGHT', 'h4': ',sa9al*[snk 0', '4': 'a', 'SJs': '{sm_J Resumir', 'Comprar': 'Lena Yulia relax girl', 'Girl': 'Radios', 'ESP': '5-23 3 cJp) LAA 5/09/2024', 'Hat': ''}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from PIL import ImageGrab, Image\n",
    "import time\n",
    "\n",
    "def wait_before_screenshot(seconds=3):\n",
    "    print(f\"Waiting {seconds} seconds before taking the screenshot...\")\n",
    "    time.sleep(seconds)\n",
    "\n",
    "def capture_full_screenshot():\n",
    "    screenshot = ImageGrab.grab()\n",
    "    return np.array(screenshot)\n",
    "\n",
    "def convert_to_grayscale(image_np):\n",
    "    return cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def initialize_ocr_reader(languages=['en', 'es', 'pt', 'it', 'fr']):\n",
    "    return easyocr.Reader(languages, gpu=False)\n",
    "\n",
    "def perform_ocr(image_np, reader):\n",
    "    return reader.readtext(image_np)\n",
    "\n",
    "def detect_chat_section(ocr_result):\n",
    "    keywords = [\"chat\", \"comments\", \"live chat\", \"live\", \"users\", \"message\", \"comentarios\", \"en vivo\"]\n",
    "\n",
    "    for (bbox, text, prob) in ocr_result:\n",
    "        text_lower = text.lower()\n",
    "        for keyword in keywords:\n",
    "            if keyword in text_lower:\n",
    "                print(f\"Detected keyword: '{keyword}' in text: '{text}'\")\n",
    "                return bbox\n",
    "\n",
    "    return None\n",
    "\n",
    "def crop_comment_section(screenshot_np, bbox, roi_left, roi_right, screen_width, screen_height):\n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    left = int(min(top_left[0], bottom_left[0])) + roi_left\n",
    "    top = int(min(top_left[1], top_right[1]))\n",
    "\n",
    "    new_bottom = min(top + 600, screen_height)\n",
    "    new_left = max(left - 20, roi_left)\n",
    "    new_right = min(left + 800, screen_width)\n",
    "\n",
    "    return screenshot_np[top:new_bottom, new_left:new_right]\n",
    "\n",
    "def save_image(image_np, file_name):\n",
    "    Image.fromarray(image_np).save(file_name)\n",
    "    print(f\"Screenshot saved as {file_name}.\")\n",
    "\n",
    "def extract_comments(ocr_result):\n",
    "    comments_dict = {}\n",
    "    lines = []\n",
    "\n",
    "    print(\"OCR result for extracted section:\")\n",
    "    for (bbox, text, prob) in ocr_result:\n",
    "        print(f\"Detected text: '{text}' with confidence {prob}\")\n",
    "        lines.append((bbox, text))\n",
    "\n",
    "    # Agrupamos los comentarios y los nombres de usuarios según la distancia vertical\n",
    "    previous_text = \"\"\n",
    "    previous_y = None\n",
    "\n",
    "    for (bbox, text) in lines:\n",
    "        # Calculamos la posición Y de la caja de la detección\n",
    "        current_y = (bbox[0][1] + bbox[2][1]) / 2\n",
    "\n",
    "        # Si la posición Y es cercana a la anterior, asumimos que es parte del mismo comentario\n",
    "        if previous_y is not None and abs(current_y - previous_y) < 20:\n",
    "            previous_text += \" \" + text  # Agregamos al comentario anterior\n",
    "        else:\n",
    "            # Guardamos el comentario si ya hay un nombre y comentario\n",
    "            if previous_text:\n",
    "                comments_dict[previous_text.split(\" \")[0]] = previous_text[len(previous_text.split(\" \")[0]):].strip()\n",
    "            previous_text = text  # Comenzamos una nueva entrada\n",
    "\n",
    "        previous_y = current_y\n",
    "\n",
    "    # Añadir el último comentario\n",
    "    if previous_text:\n",
    "        comments_dict[previous_text.split(\" \")[0]] = previous_text[len(previous_text.split(\" \")[0]):].strip()\n",
    "\n",
    "    return comments_dict\n",
    "\n",
    "def take_screenshot_of_comment_section(file_name):\n",
    "    wait_before_screenshot()\n",
    "\n",
    "    screenshot_np = capture_full_screenshot()\n",
    "    gray_screenshot = convert_to_grayscale(screenshot_np)\n",
    "\n",
    "    reader = initialize_ocr_reader()\n",
    "\n",
    "    screen_width = screenshot_np.shape[1]\n",
    "    screen_height = screenshot_np.shape[0]\n",
    "    roi_left = int(screen_width * 0.5)\n",
    "    roi_right = screen_width\n",
    "\n",
    "    cropped_screenshot = screenshot_np[:, roi_left:roi_right]\n",
    "    gray_cropped = convert_to_grayscale(cropped_screenshot)\n",
    "\n",
    "    ocr_result_cropped = perform_ocr(gray_cropped, reader)\n",
    "\n",
    "    keyword_bbox = detect_chat_section(ocr_result_cropped)\n",
    "\n",
    "    if keyword_bbox:\n",
    "        cropped_comment_section = crop_comment_section(screenshot_np, keyword_bbox, roi_left, roi_right, screen_width, screen_height)\n",
    "        save_image(cropped_comment_section, file_name)\n",
    "\n",
    "        comments_dict = extract_comments(ocr_result_cropped)\n",
    "        return comments_dict\n",
    "    else:\n",
    "        print(\"No comment section detected.\")\n",
    "        return {}\n",
    "\n",
    "# Example usage\n",
    "comments = take_screenshot_of_comment_section(\"comments_section_auto.png\")\n",
    "print(comments)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtext\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
